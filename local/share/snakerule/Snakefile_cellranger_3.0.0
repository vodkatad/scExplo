SEURAT_MARKERS="../../local/src/seurat_markers.R" # partial for compatibility with things run with old version without PCA (now re-running scRNA_Ire_cetuxi_nofilt)
include: "conf.sk"


samples_map = {}
rev_samples_map = {}
for i in range(0,len(SAMPLES)):
    samples_map[SAMPLES[i]] = OSAMPLES[i]
    rev_samples_map[OSAMPLES[i]] = SAMPLES[i]

rule pippo:
    run:
        print(samples_map)

rule all_counts:
    input: expand("{sample}.done", sample=SAMPLES)


rule cellrangercounts:
    params: transcriptome=TRANSCRIPTOME, fastq_dir=FASTQ_DIR+"{sample}", tool=CELLRANGER, mem=MEM, cores=CORES
    output: "{sample}.done"
    shell: 
        """
        {params.tool} count --localmem={params.mem} --localcores={params.cores} --transcriptome={params.transcriptome} --fastqs={params.fastq_dir} --id={wildcards.sample}
       touch {output}
        """

rule aggrcvs:
    input: expand("{sample}.done", sample=SAMPLES)
    output: "aggr.csv"
    shell:
        """
        echo 'library_id,molecule_h5' > {output}
        ls Sample_*/outs/molecule_info.h5 | perl -ane '@a=split("/",$_); print $a[0].",".$_' >> {output}
        """

rule basic_numbers:
    input: expand("{sample}/outs/metrics_summary.csv", sample=SAMPLES)
    output: csv="numbers.csv", plot="numbers.png"
    params: samplesnames=OSAMPLES
    run:
        import pandas as pd
        res = pd.DataFrame()
        j = 0
        for i in input:
            csv = pd.read_csv(i, usecols=['Estimated Number of Cells','Mean Reads per Cell','Median Genes per Cell'], dtype={'Estimated Number of Cells': str,'Mean Reads per Cell':str,'Median Genes per Cell':str})
            csv['sample'] = params.samplesnames[j]
            res = pd.concat([res, csv[['Estimated Number of Cells','Mean Reads per Cell','Median Genes per Cell','sample']] ])
            j += 1
        res.to_csv(output.csv, sep="\t", index=False)
        import seaborn as sns
        sns.set(style="white")
        res['treat'] = pd.Series(res['sample'].str.split("_", expand=True)[1]) # ehm
        res['case'] = pd.Series(res['sample'].str.split("_", expand=True)[0])
        res['cells'] = pd.Series(res['Estimated Number of Cells'].str.replace(',','')).astype(int)
        res['genes'] = pd.Series(res['Median Genes per Cell'].str.replace(',', '')).astype(int)
        sns_plot = sns.relplot(x="cells", y="genes", hue="treat", style="case", data=res)
        sns_plot.savefig(output.plot)

#egrassi@godot:/mnt/trcanmed/snaketree/prj/scRNA/dataset/scRNA_Ire_cetuxi$ ln -s Sample_S26095_501/outs/cloupe.cloupe CRC0322_NT_1.cloupe

rule all_cloupe_ln:
    input: expand("{sample}.cloupe", sample=OSAMPLES)

# I need 1hour tidying up all the different solutions for mapping samples names once and for all :(
rule cloupe_ln:
    output: "{sample}.cloupe"
    params: inp=lambda wildcards: rev_samples_map[wildcards.sample]+'/outs/cloupe.cloupe'
    shell:
        """
            ln -s {params.inp} {output}            
        """

# TODO if specific file exists in local get it otherwise link the generic one
rule seuratparams:
    output: "{sample}.params"
    input: SEURAT_PARAMS
    shell: 
        """
        ln -s {input} {output}
        """

ruleorder: seurat_cycle > seurat

# non mex per non aggr? per ora lo cambio a mano XXX TOD
# per aggr ha girato con dir="{sample}/outs/filtered_gene_bc_matrices_mex/GRCh38/ 
rule seurat:
    input: placeh="{sample}.done", pars="{sample}.params"
    params: dir="{sample}/outs/filtered_feature_bc_matrix/", name="{sample}", outdir="{sample}_seurat"
    output: outdata="{sample}_seurat/prelim.Rdata"
    script: SRC_DIR+"seurat_v3.R"

# NOTE the elbowplot in aggr_seurat is from aggr-cc due to a misshap, FIXME (right plots are on femto)

rule seurat_checkcluster:
    input: data="{sample}_seurat/prelim.Rdata", clfile="{sample}/outs/analysis/clustering/kmeans_"+str(NSAMPLES)+"_clusters/clusters.csv"
    output: "{sample}_seurat/samples_plot.pdf"
    params: osamples=OSAMPLES, outdir="{sample}_seurat"
    script: SRC_DIR+"seurat_check_v3.R"


rule seurat_cycle:
    input: data="{sample}_seurat/prelim.Rdata", cc=PRJ_ROOT+"local/share/data/regev_lab_cell_cycle_genes.txt"
    output: outdata="{sample}-cc_seurat/prelim.Rdata"
    params: outdir="{sample}-cc_seurat"
    script: SRC_DIR+"seurat_cycle_v3.R"

#Job ID: 52249
#Cluster: hactar
#User/Group: egrassi/egrassi
#State: COMPLETED (exit code 0)
#Cores: 1
#CPU Utilized: 00:30:14
#CPU Efficiency: 85.85% of 00:35:13 core-walltime
#Job Wall-clock time: 00:35:13
#Memory Utilized: 16.02 GB
#Memory Efficiency: 32.82% of 48.83 GB

# res has to be manually determined to match a sensible n. of clusters ~ to the number of cases for the aggr
rule seurat_de:
    input: data="{sample}_seurat/prelim.Rdata"
    output: out="{sample}_de_{res,0\.\d+}.tsv", outimg="{sample}_de_{res}.pdf"
    script: SRC_DIR+"seurat_DE_v3.R"
 
# gsea on seurat_de   
rule gsea_input_seurat:
    input:  "{sample}_de_{res}.tsv"
    params: debug=DEBUG
    output: "{sample}_{res,0.\d+}.gsea_seu_in"
    shell:
        """
            echo -e "geneid\\tname\\tsort" > {output}
            sed 1d {input} | bawk '{{print $7,"cl"$6,$2}}' >> {output}
        """

rule all_gsea:
    input: expand("{sample}-cc_0.5.significant_NES_gsea", sample=SAMPLES)

rule gsea_seurat:
    input: tsv="{sample}_{res}.gsea_seu_in", pathways=GSEA_PATHWAYS
    output: outdir=directory("gsea_{sample}_{res}"), outtable="{sample}_{res}.significant_NES_gsea", outtableall="{sample}_{res}.all_NES_gsea"
    params: save="gsea_{sample}_{res}.Rdata", debug=DEBUG, cores=12
    script: GSEA

rule go_input_seurat:
    input:  "{sample}_de_{res}.tsv"
    params: debug=DEBUG
    output: classes="go_{sample}_{res,0\.\d+}_seurat_input.tsv", universe="go_{sample}_{res,0\.\d+}_seurat_universe.tsv"
    shell:
        """
               sed 1d {input} | cut -f 7 | sort | uniq > {output.universe}
               sed 1d {input} | bawk '$5 < 0.005 && ($2 < -2 || $2 > 2) {{print $6,$7}}' > {output.classes}
        """

rule go_seurat:
    input: classes="go_{sample}_{res}_seurat_input.tsv", universe="go_{sample}_{res}_seurat_universe.tsv"
    output: "go_{sample}_{res}.gz"
    params: ids="symbol", onto=['BP','MF','CC'], debug=DEBUG
    script: SRC_DIR+"go.R"

####
rule all_cris:
    input: expand("{sample}_prediction_result.xls", sample=SAMPLES)

rule cris:
    input: cris=CRIS, cellranger="{sample}"
    params: prefix="{sample}",debug=DEBUG
    output: "{sample}_prediction_result.xls"
    script: SRC_DIR+"cris_classify.R"

rule all_cris_understand:
    input: expand("{sample}_classes_heatmap.png", sample=SAMPLES)

#output: heatmap="{sample}_classes_heatmap.png", tsv="{sample}_classes_table", simple="{sample}_simple"
rule cris_understand:
    input: data="{sample}.debug.RData"
    output: heatmap="{sample}_classes_heatmap.png", tsv="{sample}_classes_table"
    script: SRC_DIR+"cris_understand.R"

# snakemake -j -p aggr.done --cluster-config ../../local/src/hactar.json --cluster "sbatch --mail-user={cluster.mail-user} --mail-type={cluster.mail-type} --partition={cluster.partition} --nodes={cluster.nodes} --job-name={cluster.job-name} --output={cluster.output} --error={cluster.error} --time=24:00:00 --mem=100 --ntasks=24"
# snakemake -j -p aggr.done --cluster-config ../../local/src/hactar.json --cluster "sbatch --mail-user={cluster.mail-user} --mail-type={cluster.mail-type} --partition={cluster.partition} --nodes={cluster.nodes} --job-name={cluster.job-name} --output={cluster.output} --error={cluster.error} --time=24:00:00 --mem=100 --ntasks=24"
#    mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.
#    raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.
#    none: Do not normalize at all.
rule cellrangeraggr:
    params: tool=CELLRANGER, mem=MEM, cores=CORES
    input: "aggr.csv"
    output: "aggr.done"
    shell: 
        """
        {params.tool} aggr --localmem={params.mem} --localcores={params.cores} --id=aggr --csv={input} --normalize=mapped
        touch {output}
        """

### for line we look for expression of line-1 # how is it possible to have calls for single lines1?
# first full length (For real expr we would need to have all counts for correction...)
rule countline:
    input: expand("{sample}/outs/possorted_genome_bam.bam", sample=SAMPLES)
    output: "line.counts"
    params: cores=12, saf="/home/egrassi/line/local/share/data/line.saf"
    shell: 
        """
        featureCounts -a {params.saf} -F SAF -T {params.cores} -o {output} {input}
        """


#### gsea ####
rule all_something:
    input: expand("{sample}.{{something}}", sample=SAMPLES)
    output: "all_samples_{something}"
    shell: "touch {output}"

rule gsea_input:
    input:  clusters="{sample}/outs/analysis/diffexp/graphclust/differential_expression.csv"
    params: debug=DEBUG
    output: "{sample}.gsea_in"
    script: GSEA_INPUT

rule gsea:
    input: tsv="{sample}.gsea_in", pathways=GSEA_PATHWAYS
    output: outdir=directory("gsea_{sample}"), outtable="{sample}.significant_NES_gsea", outtableall="{sample}.all_NES_gsea"
    params: save="gsea_{sample}.Rdata", debug=DEBUG, cores=12
    script: GSEA

rule gsea_rnked_in_pathway:
    input: rdata="gsea_{sample}/gsea.Rdata"
    output: outdir="gsea_{sample}_xls_top20"
    script: GSEA_XLS

ruleorder: gsea_input_k > gsea_input
ruleorder: gsea_k > gsea
ruleorder: gsea_rnked_in_pathway_k > gsea_rnked_in_pathway
# gsea on kmeans clusters
rule gsea_input_k:
    input:  clusters="{sample}/outs/analysis/diffexp/kmeans_{k}_clusters/differential_expression.csv"
    params: debug=DEBUG
    output: "{sample}_{k,\d+}.gsea_in"
    script: GSEA_INPUT

rule gsea_k:
    input: tsv="{sample}_{k}.gsea_in", pathways=GSEA_PATHWAYS
    output: outdir=directory("gsea_{sample}_{k}"), outtable="{sample}_{k}.significant_NES_gsea"
    params: save="gsea_{sample}_{k}.Rdata", debug=DEBUG, cores=12
    script: GSEA

rule gsea_rnked_in_pathway_k:
    input: rdata="gsea_{sample}_{k}/gsea.Rdata"
    output: outdir="gsea_{sample}_{k}_xls_top20"
    script: GSEA_XLS


### go
# all differential_expression have the same length, in theory the universe could have a threshold on mean UMI...
rule go_input:
    input: clusters="{sample}/outs/analysis/diffexp/kmeans_{k}_clusters/differential_expression.csv"
    output: classes="go_{sample}_{k,\d+}_input.tsv", universe="go_{sample}_{k,\d+}_universe.tsv"
    params: pthr=0.005, lfcup=2, lfcdown=-2, debug=DEBUG
    run:
        import pandas as pd
        ref = pd.read_csv(input.clusters, sep=",")
        cols = ref.columns.values 
        #filter(lambda x: re.search(r'ID|UMI', x), cols) 
        #ref.drop(columns=cols)
        clusters = ["Cluster " + str(x) for x in range(1, (int(wildcards.k)+1))]
        classes = pd.DataFrame()
        names = ref['Gene Name'].unique()
        pd.DataFrame(names).to_csv(output.universe, sep='\t', header=False, index=False)
        for i, cl in enumerate(clusters):
            d = ref.filter(regex=cl+"|Gene", axis=1)
            cols = d.columns.values
            pval = [item for item in cols if re.search('Adjusted', item)]
            fc = [item for item in cols if re.search('fold', item)]
            gene = [item for item in cols if re.search('Gene Name', item)]
            assert len(pval) == 1 and len(fc) == 1 and len(gene) == 1, "meh about column filtering"
            up = d.loc[(d[pval[0]] < params.pthr) & (d[fc[0]] > params.lfcup)]
            down = d.loc[(d[pval[0]] < params.pthr) & (d[fc[0]] < params.lfcdown)]
            for u in up[gene[0]].unique():
                classes = classes.append({'gene': u, 'class': 'cl'+str(i)+'_up' }, ignore_index=True)
            for d in down[gene[0]].unique():
                classes = classes.append({'gene': d, 'class': 'cl'+str(i)+'_down' }, ignore_index=True)
        classes.to_csv(output.classes, sep='\t', header=False, index=False)


rule go:
    input: classes="go_{sample}_{k}_input.tsv", universe="go_{sample}_{k}_universe.tsv"
    output: "go_{sample}_{k}.gz"
    params: ids="symbol", onto=['BP','MF','CC'], debug=DEBUG
    script: SRC_DIR+"go.R"


### single sample markers

### cellranger 2csv
#(base) [outs]egrassi@hactarlogin$ ../../../../local/src/cellranger-3.1.0/cellranger mat2csv filtered_feature_bc_matrix.h5 test.csv
rule all_tsv:
    input: expand("{sample}.tsv", sample=SAMPLES[0:])


rule tocsv:
    params: tool=CELLRANGER, out=lambda wildcards: samples_map[wildcards.sample]+".tsv"
    input: "{sample}/outs/filtered_feature_bc_matrix.h5"
    output: "{sample}.tsv"
    shell: 
        """
        {params.tool} mat2csv {input} {output}
        cp {output} {params.out}
        """

rule all_csv: 
    input: expand("{sample}_cellranger.csv", sample=OSAMPLES)

def find_csv_ln(wildcards):
    import os
    i = OSAMPLES.index(wildcards.sample)
    w = SAMPLES[i] + ".tsv"
    print(w)
    if os.path.isfile(w):
        return w
    else:
        raise ValueError("Check you SAMPLES_ORIG and SAMPLES in conf.sk!")
            
rule csvln:
    input: find_csv_ln
    output: "{sample}_cellranger.csv"
    shell:
        """
            ln -s {input} {output}
        """
    
# FQ removed is needed to avoid failures when the original fq have been moved to make space
def find_ln(wildcards):
    import os
    print(wildcards.sample)
    i = OSAMPLES.index(wildcards.sample)
    w = SAMPLES[i] + "_seurat/prelim.Rdata"
    print(w)
    if os.path.isfile(w):
        return w
    else:
        raise ValueError("Check you SAMPLES_ORIG and SAMPLES in conf.sk!")
           
rule ln:
    input: find_ln
    output: "{sample}_Seurat_prelim.Rdata"
    shell:
        """
            ln -s {input} {output}
        """

rule all_markers:
    input: expand("{sample}_0.2.clusters_markers.tsv", sample=OSAMPLES)


rule seurat_markers:
    input: data="{sample}_Seurat_prelim.Rdata", cc=PRJ_ROOT+"local/share/data/regev_lab_cell_cycle_genes.txt"
    output: markers="{sample}_{res}.clusters_markers.tsv", cyclecl="{sample}_{res}.cycle_cluster.tsv", heatmap="{sample}_{res}.heat.pdf", umapcl="{sample}_{res}.umap_cl.pdf",
            umapcy="{sample}_{res}.umap_cy.pdf"
    script: SEURAT_MARKERS

# TODO clone rule to get % mito and decide if we need to re-run or not

# paneth:
# 327 nt 1 - 4
# 327 cetuxi 1 - 3
# 327 nt 2 - 6
# 327 cetuxi 2 - 3
# 322 nt 1 - 3
# 322 cetuxi 1 - 2
# 1502 nt 1 - 4 
# 1502 cetuxi 1 - 3
rule paneth_cells:
    input: expand("{sample}_0.2.cycle_cluster.tsv", sample=OSAMPLES)
    output: "paneth_cells_cycle.tsv"
    run:
        cl = {
            "CRC0327_NT_1": "4", "CRC0327_cetux_1": "3", "CRC0322_NT_1": "3", "CRC0322_cetux_1": "2", "CRC0327_NT_2": "6", "CRC0327_cetux_2": "3", "CRC1502_NT_1": "4", "CRC1502_cetux_1": "3"
        }
        with open(output[0],'w') as out:
            for k in cl.keys():
                with open(k+"_0.2.cycle_cluster.tsv", 'r') as w:
                    w.readline()
                    for l in w.readlines():
                        l = l.rstrip()
                        fields = l.split("\t")
                        #print(fields[2])
                        if fields[2] == cl.get(k):
                            out.write(l+"\t"+k+"\n")

# get list of cell to color global rorshack

rule match_clusters:
    input: expand("{sample}_0.2.clusters_markers.tsv", sample=OSAMPLES)
    output: "TODO"
    shell:
        """
            TODO
        """

# probably not ok cause we have a threshold for logFC :()
rule gsea_input_markers:
    input: "{sample}_0.2.clusters_markers.tsv"
    output: "{sample}.markers.gsea_in"
    shell:
        """
            echo -e "geneid\\tname\\tsort" > {output}
            sed 1d {input} | bawk '{{print $8,"cl"$7,$3}}' >> {output}
        """

rule gsea_markers:
    input: tsv="{sample}.markers.gsea_in", pathways=GSEA_PATHWAYS
    output: outdir=directory("gsea_markers-{sample}"), outtable="{sample}.markers.significant_NES_gsea", outtableall="{sample}.markers.NES_GSEA.tsv"
    params: save="gsea_markers_{sample}.Rdata", debug=DEBUG, cores=12
    script: GSEA


# y 0.02?
rule go_input_markers:
    input: "{sample}_0.2.clusters_markers.tsv"
    output: i="markersgo_{sample}.input.tsv", u="markersgo_{sample}.universe.tsv"
    shell:
        """
            sed 1d {input} | bawk '$6<0.02{{print "cl"$7,$8}}' > {output.i}
            sed 1d {input} | bawk '{{print $8}}' |sort |uniq > {output.u}
        """

rule go_markers:
    input: classes="markersgo_{sample}.input.tsv", universe="markersgo_{sample}.universe.tsv"
    output: "markersgo_{sample}.gz"
    params: ids="symbol", onto=['BP','MF','CC'], debug=DEBUG
    script: SRC_DIR+"go.R"

rule paneth_markers:
    input: expand("{sample}_0.2.clusters_markers.tsv", sample=OSAMPLES)
